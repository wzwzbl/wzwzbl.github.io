<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>python爬虫day05 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="python爬虫库总结（1）selenium   （用来爬抖音视频，谷歌浏览器） 是动态渲染页面的爬虫用来模拟人工滑动，页面的情况from selenium import webdriverChrome浏览器驱动：chromedriver , taobao备用地址driver &#x3D; webdriver.Chrome()    # Chrome浏览器元素定位find_element_by_css_se">
<meta property="og:type" content="article">
<meta property="og:title" content="python爬虫day05">
<meta property="og:url" content="http://example.com/2022/02/08/python%E7%88%AC%E8%99%AB%E7%94%A8%E5%88%B0%E7%9A%84%E5%BA%93/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="python爬虫库总结（1）selenium   （用来爬抖音视频，谷歌浏览器） 是动态渲染页面的爬虫用来模拟人工滑动，页面的情况from selenium import webdriverChrome浏览器驱动：chromedriver , taobao备用地址driver &#x3D; webdriver.Chrome()    # Chrome浏览器元素定位find_element_by_css_se">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-02-08T10:43:52.000Z">
<meta property="article:modified_time" content="2022-03-18T15:49:13.712Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-python爬虫用到的库" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/02/08/python%E7%88%AC%E8%99%AB%E7%94%A8%E5%88%B0%E7%9A%84%E5%BA%93/" class="article-date">
  <time class="dt-published" datetime="2022-02-08T10:43:52.000Z" itemprop="datePublished">2022-02-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      python爬虫day05
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>python爬虫库总结<br>（1）selenium   （用来爬抖音视频，谷歌浏览器） 是动态渲染页面的爬虫<br>用来模拟人工滑动，页面的情况<br>from selenium import webdriver<br>Chrome浏览器驱动：chromedriver , taobao备用地址<br>driver = webdriver.Chrome()    # Chrome浏览器<br>元素定位<br>find_element_by_css_selector() 格式： div.knrjsN15 &gt; div:nth-child(2)&gt;ul li<br>find_element_by_xpath()   格式 //*[@id=”root”]/div/div[2]/div/div/div[4]/div[1]/div[2]/ul/li[1]<br>（2）bs4库 （用来爬小说，爬取音乐）<br>from bs4 import BeautifulSoup </p>
<p>BeautifulSoup是将HTML代码当做一个便签树来处理，BeautifulSoup对应一个HTML/XML文档的全部内容 。其中的每一个标签的结构如下：<br>soup = BeautifulSoup(r.text, “html.parser”)<br> data = []<br>    for h2 in soup.find_all(“h2”):   #  找所有的h2<br>        link = h2.find(“a”)               #遍历h2下面的a<br>        if not link:<br>            continue<br>        data.append((“https:%s” % link[‘href’], link[‘title’]))<br>    return data<br>除了find_all()方法，还有find()方法，只不过find()方法返回的是单个的标签，也就是第一个匹配的标签，而find_all()方法返回的是所有匹配的标签组成的列表。<br>（3）xpath库<br>pip install lxml<br>from lxml import etree<br>使用Xpath解析HTML文本<br>html = etree.HTML(text, etree.HTMLParser())<br>result = html.xpath(‘/html/head/title/text()’)<br>print(result)<br>（4）pyquery<br>from pyquery import PyQuery as pq    # 将字符串初始化为pyquery对象<br>doc = pq(response)<br>    figure = doc(‘.  ‘).items()  #查找class里的东西<br>    for i in figure:<br>        video_url = i.attr(‘href’)       遍历figure 找到href里的视频连接</p>
<p>doc = pq(text)<br>print(doc(‘b’))<br>运行结果：<br><b link="af"/><br><b link="bba"/><br>（5）re 正则表达式<br>(.*?)<br>re.compile(,re.S)<br>re.findall()<br>re.sub(‘’,’’,’’)<br>(6)  parsel<br>selector = parsel.Selector(rea)<br>lis = selector.css(‘.grid_view li’)   #’.grid_view li’ 是在class =grid_view下的li<br>title = ls.css(‘.info .hd span.title:nth-child(1)::text’).get()  #:nth-child(1)查找第一个<br>（7）csv 保存为csv格式<br>import csv<br>f = open(‘豆瓣top250.csv’, mode=’a’, encoding=’utf-8-sig’, newline=’’)<br>csv_writer=csv.DictWriter(f, fieldnames=[     #写的所有的开头<br>    ‘标题’,<br>    ‘导演’,<br>    ‘演员’,<br>    ‘电影年份’,<br>    ‘国家’,<br>    ‘类型’,<br>    ‘电影简介’,<br>    ‘电影评分’,<br>    ‘评价人数’<br>])<br>csv_writer.writeheader()  #在代码开头写是csv是头文件<br>csv_writer.writerow(dit) #在结尾写是写如csv要传入的东西<br>（8）josnpath 数据提取方法，提取josn数据<br> ‘’’<br>import jsonpath<br>import requests<br>import json<br>url = ‘<a target="_blank" rel="noopener" href="https://www.lagou.com/lbs/getAllCitySearchLabels.json&#39;">https://www.lagou.com/lbs/getAllCitySearchLabels.json&#39;</a><br>headers = {<br>    ‘user-agent’: ‘Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.81 Safari/537.36’<br>}</p>
<p>resa =requests.get(url=url,headers=headers)<br>city_data=resa.content.decode()<br>print(city_data)<br>city_data_dict = json.loads(city_data)<br>print(jsonpath.jsonpath(city_data_dict,”$..B..name”) )</p>
<p>‘’’</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/02/08/python%E7%88%AC%E8%99%AB%E7%94%A8%E5%88%B0%E7%9A%84%E5%BA%93/" data-id="cl9badkte000ygsuq45tr9v6t" data-title="python爬虫day05" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/02/09/python%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8Bday05/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          python爬虫实例day06
        
      </div>
    </a>
  
  
    <a href="/2022/02/08/python%E7%88%AC%E8%99%AB%E5%AE%9E%E4%BE%8Bday04/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">python爬虫实例day04</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">October 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/10/13/k8s%E9%83%A8%E7%BD%B2/">k8s部署</a>
          </li>
        
          <li>
            <a href="/2022/10/13/docker%E9%83%A8%E7%BD%B2/">docker部署</a>
          </li>
        
          <li>
            <a href="/2022/10/10/zabbix/">zabbix</a>
          </li>
        
          <li>
            <a href="/2022/10/08/mysql%E4%B8%BB%E4%BB%8E%E6%9C%8D%E5%8A%A1/">mysql主从服务</a>
          </li>
        
          <li>
            <a href="/2022/03/17/redis%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E4%B8%8E%E9%9B%AA%E5%B4%A9/">redis缓存穿透与雪崩</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>